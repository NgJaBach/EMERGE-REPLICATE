{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5ab9487f",
   "metadata": {},
   "source": [
    "# A. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2335e56b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "\n",
    "RANDOM_STATE = 42  # for reproducibility"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e255b2ac",
   "metadata": {},
   "source": [
    "# B. Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "264d45b3",
   "metadata": {},
   "source": [
    "## Keep only first episode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "652b6ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_patient_ids(INPUT_CSV, OUTPUT_CSV):\n",
    "    df = pd.read_csv(INPUT_CSV)\n",
    "    pid = df[\"PatientID\"].astype(str)\n",
    "    extracted = pid.str.extract(r\"^(?P<base>\\d+)(?:_(?P<suf>\\d+))?$\")\n",
    "\n",
    "    # Determine which rows to keep:\n",
    "    # - Keep if suffix is NaN (no suffix) or equals 1\n",
    "    # - Drop if suffix is >= 2\n",
    "    suf_num = pd.to_numeric(extracted[\"suf\"], errors=\"coerce\")\n",
    "    keep_mask = suf_num.isna() | (suf_num == 1)\n",
    "    clean = df.loc[keep_mask].copy()\n",
    "    clean.loc[:, \"PatientID\"] = extracted.loc[keep_mask, \"base\"].astype(str)\n",
    "    clean.to_csv(OUTPUT_CSV, index=False)\n",
    "\n",
    "    # print(\"Before:\")\n",
    "    # print(df.head(3))\n",
    "    # print(\"\\nAfter (cleaned):\")\n",
    "    # print(clean.head(3))\n",
    "\n",
    "clean_patient_ids(\"raw/notes.csv\", \"processed/notes.csv\")\n",
    "clean_patient_ids(\"raw/ehr.csv\", \"processed/ehr.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f776e3f",
   "metadata": {},
   "source": [
    "## Keep only patients with both ehr and notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b75076ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== BEFORE ===\n",
      "Notes: 204,008 rows | 31,027 unique patients\n",
      "EHR  : 242,217 rows | 33,469 unique patients\n",
      "\n",
      "=== AFTER (kept only patients present in BOTH) ===\n",
      "Common patients kept: 31,027\n",
      "Notes.filtered.csv: 204,008 rows | 31,027 patients\n",
      "ehr.filtered.csv  : 231,100 rows | 31,027 patients\n"
     ]
    }
   ],
   "source": [
    "NOTES_PATH = \"processed/notes.csv\"\n",
    "EHR_PATH   = \"processed/ehr.csv\"\n",
    "NOTES_OUT  = \"processed/notes.csv\"\n",
    "EHR_OUT    = \"processed/ehr.csv\"\n",
    "\n",
    "notes = pd.read_csv(NOTES_PATH, dtype={\"PatientID\": \"string\"})\n",
    "ehr   = pd.read_csv(EHR_PATH,   dtype={\"PatientID\": \"string\"})\n",
    "\n",
    "# normalize IDs a bit (handle stray spaces / empty)\n",
    "notes[\"PatientID\"] = notes[\"PatientID\"].str.strip()\n",
    "ehr[\"PatientID\"]   = ehr[\"PatientID\"].str.strip()\n",
    "notes = notes.dropna(subset=[\"PatientID\"])\n",
    "ehr   = ehr.dropna(subset=[\"PatientID\"])\n",
    "\n",
    "# ---- find intersection ----\n",
    "ids_notes = set(notes[\"PatientID\"].unique())\n",
    "ids_ehr   = set(ehr[\"PatientID\"].unique())\n",
    "ids_both  = ids_notes & ids_ehr\n",
    "\n",
    "# ---- filter to the same set ----\n",
    "notes_f = notes[notes[\"PatientID\"].isin(ids_both)].copy()\n",
    "ehr_f   = ehr[ehr[\"PatientID\"].isin(ids_both)].copy()\n",
    "\n",
    "# ---- (optional) sort for readability ----\n",
    "notes_f = notes_f.sort_values([\"PatientID\"]).reset_index(drop=True)\n",
    "ehr_f   = ehr_f.sort_values([\"PatientID\"]).reset_index(drop=True)\n",
    "\n",
    "# ---- save ----\n",
    "notes_f.to_csv(NOTES_OUT, index=False)\n",
    "ehr_f.to_csv(EHR_OUT,   index=False)\n",
    "\n",
    "# ---- report ----\n",
    "print(\"=== BEFORE ===\")\n",
    "print(f\"Notes: {len(notes):,} rows | {len(ids_notes):,} unique patients\")\n",
    "print(f\"EHR  : {len(ehr):,} rows | {len(ids_ehr):,} unique patients\")\n",
    "print(\"\\n=== AFTER (kept only patients present in BOTH) ===\")\n",
    "print(f\"Common patients kept: {len(ids_both):,}\")\n",
    "print(f\"Notes.filtered.csv: {len(notes_f):,} rows | {notes_f['PatientID'].nunique():,} patients\")\n",
    "print(f\"ehr.filtered.csv  : {len(ehr_f):,} rows | {ehr_f['PatientID'].nunique():,} patients\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a1177da",
   "metadata": {},
   "source": [
    "# C. Check"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cf9c213",
   "metadata": {},
   "source": [
    "## Check Notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cecaad6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üåç Overall stats:\n",
      "{'max_chars': 15389, 'avg_chars': np.float64(1177.5311752480295), 'max_words': 3716, 'avg_words': np.float64(224.1933600643112)}\n"
     ]
    }
   ],
   "source": [
    "# --- Load the CSV ---\n",
    "df = pd.read_csv(\"processed/notes.csv\")\n",
    "\n",
    "# --- Functions to count ---\n",
    "def char_count(text):\n",
    "    return len(text)\n",
    "\n",
    "def word_count(text):\n",
    "    return len(text.split())\n",
    "\n",
    "# --- Apply counts ---\n",
    "df[\"char_count\"] = df[\"Text\"].astype(str).apply(char_count)\n",
    "df[\"word_count\"] = df[\"Text\"].astype(str).apply(word_count)\n",
    "\n",
    "# --- Overall stats ---\n",
    "overall = {\n",
    "    \"max_chars\": df[\"char_count\"].max(),\n",
    "    \"avg_chars\": df[\"char_count\"].mean(),\n",
    "    \"max_words\": df[\"word_count\"].max(),\n",
    "    \"avg_words\": df[\"word_count\"].mean(),\n",
    "}\n",
    "\n",
    "print(\"\\nüåç Overall stats:\")\n",
    "print(overall)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "317e924d",
   "metadata": {},
   "source": [
    "## Check EHR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb62e9b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (231100, 64)\n",
      "Outcome positive ratio (per patient, ANY episode): 0.14751622674167028\n",
      "Readmission positive ratio (per patient, ANY episode): 0.19244482907832108\n",
      "Outcome positive ratio (per patient, ANY episode): 0.1043284880910175\n",
      "Readmission positive ratio (per patient, ANY episode): 0.13539820156637766\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"processed/ehr.csv\")\n",
    "print(\"Shape:\", df.shape)\n",
    "\n",
    "pat_any = df.groupby(\"PatientID\")[[\"Outcome\",\"Readmission\"]].max()\n",
    "\n",
    "print(\"Outcome positive ratio (per patient, ANY episode):\", pat_any[\"Outcome\"].mean())\n",
    "print(\"Readmission positive ratio (per patient, ANY episode):\", pat_any[\"Readmission\"].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a8d42a7",
   "metadata": {},
   "source": [
    "# D. Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a05e5203",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patient counts per joint class (O*2+R): Counter({0: 26775, 3: 3186, 1: 1015, 2: 51})\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('processed/ehr.csv')\n",
    "\n",
    "pat = (\n",
    "    df.groupby('PatientID', as_index=False)\n",
    "      .agg(\n",
    "          Outcome=('Outcome','first'),\n",
    "          Readmission=('Readmission','first')\n",
    "      )\n",
    ")\n",
    "\n",
    "pat['joint'] = pat['Outcome'].astype(int)*2 + pat['Readmission'].astype(int)\n",
    "print(\"Patient counts per joint class (O*2+R):\", Counter(pat['joint']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cea9356e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21718, 3103, 6206)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1) Hold out 20% for TEST\n",
    "pat_trainval, pat_test = train_test_split(\n",
    "    pat,\n",
    "    test_size=0.20,\n",
    "    stratify=pat['joint'],\n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "# 2) From the remaining 80%, carve out 12.5% as VAL  (12.5% of 80% = 10% overall)\n",
    "pat_train, pat_val = train_test_split(\n",
    "    pat_trainval,\n",
    "    test_size=0.125,\n",
    "    stratify=pat_trainval['joint'],\n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "len(pat_train), len(pat_val), len(pat_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "753eb666",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: rows=162,298, patients=21,718\n",
      "Val: rows=22,577, patients=3,103\n",
      "Test: rows=46,225, patients=6,206\n"
     ]
    }
   ],
   "source": [
    "train_ids = set(pat_train['PatientID'])\n",
    "val_ids   = set(pat_val['PatientID'])\n",
    "test_ids  = set(pat_test['PatientID'])\n",
    "\n",
    "train_df = df[df['PatientID'].isin(train_ids)].copy()\n",
    "val_df   = df[df['PatientID'].isin(val_ids)].copy()\n",
    "test_df  = df[df['PatientID'].isin(test_ids)].copy()\n",
    "\n",
    "for name, d in [('Train', train_df), ('Val', val_df), ('Test', test_df)]:\n",
    "    print(f\"{name}: rows={len(d):,}, patients={d['PatientID'].nunique():,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ae93a39c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train ‚Äî Outcome: rows=14.756%, patients=10.434% | Readmission: rows=19.348%, patients=13.542%\n",
      "Val ‚Äî Outcome: rows=16.056%, patients=10.442% | Readmission: rows=19.870%, patients=13.535%\n",
      "Test ‚Äî Outcome: rows=14.098%, patients=10.425% | Readmission: rows=18.577%, patients=13.535%\n",
      "Train joint distribution (O*2+R): {0: '86.29%', 3: '10.27%', 1: '3.27%', 2: '0.17%'}\n",
      "Val joint distribution (O*2+R): {0: '86.30%', 3: '10.28%', 1: '3.25%', 2: '0.16%'}\n",
      "Test joint distribution (O*2+R): {0: '86.30%', 3: '10.26%', 1: '3.27%', 2: '0.16%'}\n"
     ]
    }
   ],
   "source": [
    "def summarize_split(name, df_rows, df_pat):\n",
    "    # Row-level percentages\n",
    "    o_row = df_rows['Outcome'].mean()\n",
    "    r_row = df_rows['Readmission'].mean()\n",
    "    # Patient-level percentages\n",
    "    o_pat = df_pat['Outcome'].mean()\n",
    "    r_pat = df_pat['Readmission'].mean()\n",
    "    print(f\"{name} ‚Äî Outcome: rows={o_row:.3%}, patients={o_pat:.3%} | \"\n",
    "          f\"Readmission: rows={r_row:.3%}, patients={r_pat:.3%}\")\n",
    "\n",
    "summarize_split(\"Train\", train_df, pat_train)\n",
    "summarize_split(\"Val\",   val_df,   pat_val)\n",
    "summarize_split(\"Test\",  test_df,  pat_test)\n",
    "\n",
    "# Also show joint-label distribution at patient level for each split\n",
    "for name, p in [(\"Train\", pat_train), (\"Val\", pat_val), (\"Test\", pat_test)]:\n",
    "    counts = Counter(p['joint'])\n",
    "    total = len(p)\n",
    "    frac = {k: f\"{v/total:.2%}\" for k,v in counts.items()}\n",
    "    print(f\"{name} joint distribution (O*2+R):\", frac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e9181431",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved splits/train.csv, splits/val.csv, splits/test.csv\n"
     ]
    }
   ],
   "source": [
    "train_df.to_csv('splits/train.csv', index=False)\n",
    "val_df.to_csv('splits/val.csv', index=False)\n",
    "test_df.to_csv('splits/test.csv', index=False)\n",
    "print(\"Saved splits/train.csv, splits/val.csv, splits/test.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
